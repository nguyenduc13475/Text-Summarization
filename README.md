# Text Summarization Project (CO3101)

**NhÃ³m thá»±c hiá»‡n:**
- Nguyá»…n VÄƒn Äá»©c - 2310790

Dá»± Ã¡n nÃ y lÃ  Ä‘á»“ Ã¡n tá»•ng há»£p cá»§a há»c pháº§n **HÆ°á»›ng trÃ­ tuá»‡ nhÃ¢n táº¡o (CO3101)**, vá»›i Ä‘á» tÃ i **Text Summarization**.  
NhÃ³m hiá»‡n thá»±c vÃ  so sÃ¡nh nhiá»u mÃ´ hÃ¬nh hiá»‡n Ä‘áº¡i trong tÃ³m táº¯t vÄƒn báº£n, Ä‘á»“ng thá»i tÃ­ch há»£p thÃªm má»™t sá»‘ phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng Ä‘á»ƒ Ä‘á»‘i chiáº¿u káº¿t quáº£.

---

## ğŸ“Œ CÃ¡c mÃ´ hÃ¬nh chÃ­nh

- **Pointer Generator Network with Coverage**
- **Neural Intra Attention Model**  
  (sá»­ dá»¥ng má»¥c tiÃªu há»—n há»£p: Reinforcement Learning loss + Negative Log-Likelihood loss)
- **Transformer**

NgoÃ i ra, nhÃ³m cÅ©ng cÃ i Ä‘áº·t **TextRank** Ä‘á»ƒ tham kháº£o.

---

## ğŸ“‚ Tokenizer sá»­ dá»¥ng

- **Pointer Generator Network** vÃ  **Neural Intra Attention Model**:  
  Sá»­ dá»¥ng **Word-level tokenizer** vá»›i tá»« vá»±ng trong file `word_level_vocab.json` (25,000 token).
- **Transformer**:  
  Sá»­ dá»¥ng **ByteLevelBPETokenizer** vá»›i file `merges.txt` vÃ  `vocab.json` (50,000 token).

---

## ğŸ“Š Dataset

NhÃ³m sá»­ dá»¥ng **CNN/Daily Mail Dataset** gá»“m:
- **Train**: 287,113 samples  
- **Validation**: 13,368 samples  
- **Test**: 11,490 samples  

Má»—i sample cÃ³ cáº¥u trÃºc:
```json
{
  "id": "string",
  "article": "string vÄƒn báº£n gá»‘c",
  "highlights": "string tÃ³m táº¯t"
}
```

---

## ğŸ’¾ Checkpoints

- Táº¥t cáº£ checkpoint Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c:
```
<TÃªn_Model>_checkpoints/
```

---

## ğŸš€ HÆ°á»›ng dáº«n cháº¡y

### 1. CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t
```bash
pip install -r requirements.txt
```

### 2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh
```bash
python training.py
```
> CÃ¡c tham sá»‘ huáº¥n luyá»‡n cÃ³ thá»ƒ chá»‰nh trá»±c tiáº¿p trong file `training.py`.

### 3. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
```bash
python evaluation.py
```
> CÃ¡c tham sá»‘ Ä‘Ã¡nh giÃ¡ cÃ³ thá»ƒ chá»‰nh trong file `evaluation.py`.

### 4. Suy luáº­n (Inference) vá»›i Beam Search
```bash
python inference.py
```
> CÃ¡c tham sá»‘ cÃ³ thá»ƒ chá»‰nh trong file `inference.py`.

### 5. Cross Validation cho Hyperparameter Tuning
```bash
python cross_validation.py
```
> CÃ¡c tham sá»‘ cÃ³ thá»ƒ chá»‰nh trong file `cross_validation.py`.

### 6. Cháº¡y TextRank
```bash
python text_rank.py
```

---

## âš™ï¸ Ná»n táº£ng cháº¡y

- CÃ³ thá»ƒ cháº¡y trÃªn **local machine** hoáº·c **Google Colab**.  
- Há»— trá»£ cáº£ **CPU** vÃ  **GPU** (khuyáº¿n nghá»‹ GPU Ä‘á»ƒ tÄƒng tá»‘c huáº¥n luyá»‡n).

---

## ğŸ“ˆ Metrics Ä‘Ã¡nh giÃ¡

CÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh:
- **ROUGE-1**
- **ROUGE-2**
- **ROUGE-L**
- **BLEU-4**
- **METEOR**
- **BERTScore**
- **MoverScore**

---
